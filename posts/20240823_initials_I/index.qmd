---
title: "When initials collide (I)"
subtitle: "A random exploration of first and family name initials"
description: "Two-letter initials, setting the scene"
author: "Guido Huyberechts"
date: "2024-08-23"
date-modified: last-modified
reading-time: true
file-modified: true
draft: false
freeze: true
image: "img/chunk03_1_thumb.png"
categories: [statistics, fun, EN]
engine: knitr
lang: en 
---

```{css}
#| echo: false
p {
text-align: justify
}
figcaption {
  margin: auto;
  text-align: center;
}
```

## Introduction

When I wander around the internet, there are several places where I tend to linger a little longer. One of them is the blog of Antoine Soetewey ("AS"): Stats and R[^1]. This time my attention was drawn by the post of 2023-12-06, about the probability of two people in a meeting or team having the same initials[^2].

This is the introduction of the "problem", in Antoine's words:

> _Last week, I joined a team to work on a collaborative project. The team was already established for a few months, with several scientists working together on the project. For simplicity, they used to sign documents, mention colleagues in emails, etc. with their initials (the first letter of their first name followed by the first letter of their last name).  
_  
> _A couple of days after joining the project, when I needed to sign my first document with my initials, we realized that another person in the team had the exact same initials than me._
> _This was not really an issue, as we decided that I would write my initials backward, that is, “SA” instead of “AS”, and the other person would keep signing with “AS” as usual.  
_  
> _It could have stopped here. However, the idea to write a post about this rather trivial anecdote came to me when the team leader claimed, in the middle of a meeting: “That’s very unfortunate that you two have the same initials! What are the chances of this happening to us?!”.
We spent a couple of minutes trying to estimate this probability, which in the end were mostly based on our intuitions rather than on a formal calculation. This piqued my curiosity._

And my curiosity as well ... for several reasons:


```{r}
#| echo: false                     # hide code printing in output doc
#| warning: false                  # hide warnings in output doc
#| message: false                  # hide messages in output doc
#
library (uuid)
as <- paste0("as-", UUIDgenerate(use.time = NA, n = 1L, output = c("string", "raw", "uuid")))
```

- When signing documents, pages, and e-mails, can one not just use unique digital signatures these days? But that spoils the question of course. 
- When using paper and pen for writing, are the initials in written form (paraph) not sufficiently different? Maybe fine for old-school legal documents and signoff lists, but in daily e-mails and meeting minutes? Nah.
- Why not use four characters? Actually, that is the origin of this blog's name. The abbreviation for my name as it was used in a company. We also used that system for minutes of meetings with externals. A meeting with Antoine would then have ASOE and GHUY after the names in the attendance list, in the abbreviation of names mentioned in the text and in the action list for instance.
- Or go the full way: `{r} as`    

The latter, combining the initials with a unique UUID (or GUID)[^3], is certainly the best regarding uniqueness. A bit hard to memorise... The UUID is generated by an R package[^4] as an exercise.

>_Given that the project we are working on requires the use of simulations, I decided to focus on answering this question via simulations in R. That being said, as for most simulations, it is a good practice to verify these results. This is done using probability theory. This comparison will allow to assess the truthfulness of results obtained through simulations.  
_  
>_Furthermore, I thought that it would be a nice way to illustrate methods not often presented in my posts: for loops, replications and writing functions in R.  
_

I would like to reflect somewhat more on this problem, but I do not intend to copy his whole blog page, so please look at Antoine's [original post](https://statsandr.com/) for details first.  

## Reflections on the results

Welcome back... 

Let's summarize the conditions and results.

- AS starts, for his team of eight persons, by creating a vector of size eight, corresponding to the initials of each of the team members.   
- It is checked whether there are duplicate initials.  
- It is estimated, via simulations, how likely it is that at least two persons have the same initials among the team. So the vector of eight sampled initials is replicated (or rather re-drawn) a large number of times, namely 1000 times.  

A matrix of eight rows and 1000 columns is the result. Each row corresponds to the sampled initials of a person, and each column corresponds to one simulated team of 8 people. It remains to compute how many of these 1000 teams have at least two persons with the same initials. Under the given conditions it was 41. It can be stated that the probability of having duplicate initials is 4.1 %. 

As the construction of the teams is a random process, this probability will vary each time a simulation is run. In the end, 100 simulations were carried out and returned a list of 100 probabilities. AS shows a histogram and a boxplot to demonstrate that the probability that at least two persons share the same initials among a team of 8 people is most likely between 3.5% and 4.5%. 

We could use his data, with permission, to calculate the mean as well.


```{r}
#| echo: true                      # show code in output doc
#| warning: false                  # hide warnings in output doc
#| message: false                  # hide messages in output doc
# ==============================================================================
# Calculate mean and standard deviation for AS' 100 replicate data
#
d_as <- c(0.032, 0.037, 0.040, 0.043, 0.033, 0.042, 0.039, 0.047, 0.045, 0.038, 0.052, 0.042,
          0.042, 0.040, 0.023, 0.044, 0.041, 0.039, 0.036, 0.048, 0.041, 0.037, 0.027, 0.030,
          0.052, 0.038, 0.043, 0.035, 0.038, 0.045, 0.047, 0.044, 0.030, 0.036, 0.036, 0.048,
          0.038, 0.045, 0.044, 0.034, 0.031, 0.043, 0.045, 0.034, 0.049, 0.047, 0.051, 0.036,
          0.051, 0.040, 0.043, 0.044, 0.038, 0.049, 0.043, 0.050, 0.035, 0.043, 0.048, 0.038,
          0.041, 0.044, 0.039, 0.045, 0.033, 0.057, 0.036, 0.043, 0.041, 0.041, 0.041, 0.041,
          0.038, 0.044, 0.031, 0.034, 0.049, 0.041, 0.040, 0.034, 0.032, 0.036, 0.049, 0.047,
          0.048, 0.038, 0.038, 0.037, 0.036, 0.037, 0.043, 0.040, 0.026, 0.049, 0.046, 0.044,
          0.048, 0.038, 0.026, 0.029)
n_as <- length(d_as)
m_as <- mean(d_as)
s_as <- sd(d_as)
#
```

Based on the data, a mean of `{r} round(100*m_as,digits=2)` % is observed, with a standard deviation of `{r} round(100*s_as,digits=2)` %.

It is possible to compare this result obtained through simulations with results obtained from probability theory. In fact, AS reports that the number of possible two-letter initials (TLI) in the case of a team of 8 persons is 4.07218 %.

Of course this brings up an obvious question: why simulate and come to variable results (due to the random nature) if one can calculate the exact result from probability theory? For me at least, a satisfying answer is that we can prove that the same result can be obtained, giving confidence to the simulation method under conditions where the result could not be calculated analytically in a convenient way, or not at all.

But also other questions arise. Is the result close enough to the true value? What is the effect of the number of re-draws?

Furthermore, the two-letter initials are generated by random selection of a first initial and random selection of a second initial, both from the list of 26 characters of the Latin alphabet. It is mentioned by AS that _"all letters of the alphabet had the same probability of occurring, meaning that all pairs of initials were equally probable. This is probably not the case in reality, as a first and last name starting both with X is not as probable as a first and last name starting respectively with M and K."_ Now this also makes a nice case and in fact makes the whole question, or better the solution, pretty region dependent. Imagine for instance parts of the world where a lot of people have names like Kim, Nguyen, etc.  
 
And when we go from two-letter to four-letter initials, we need the actual family names, as a random selection of three characters is not really realistic in real life. Well, not sure what the future brings (considering names like X Æ A-Xii). Well, some mothers (and fathers) do have them, as they used to say. And in areas with frequently occuring family names, it remains a problem of course.

As AS states: this bias could be limited by specifying different weights when sampling initials.  

## Variation on a theme
### Setting the scene

Well, we differ somewhat in taste. Probably because I am more of an experimenter and not really a mathematician nor statistician, but repeats and replicates could be better defined in my opinion. With replicates experimenters (in chemical analysis for instance) point to the execution of a lab experiment/analysis under exact the same conditions. In the case of a simulation experiment this would correspond to the use of the same sequence of random numbers. This will then also give exactly the same result. So repeats, with different random numbers, are to be considered. 

To avoid confusion, and for the purpose of this post, I will consider the random selection of two-letter initials as drawing M&M-like[^m] candies from a huge[^mm] bag containing candies with all possible combinations of _two letters_ printed on them. Obviously: I call the determination of one random two-letter initial a _draw of a two-letter initial_. In the same context I call the _draw of a team_ the drawing (with putting back after each two-letter initial) of eight M&M's. I have a _number of repeats_, in order to allow the determination of the probability of having duplicate two-letter initials and the _number of experiments_ to indicate how many times the number of repeats is carried out. Recall that, in our definitions, AS used 1000 as number of repeats and 100 as number of experiments.

### Adapting the code to my taste

I will further explore some aspects of the same type of simulation. So let's start with a variation on the theme. At first, the letters are randomly sampled among all 26 letters of the Latin alphabet. The code below does essentially the same as in the _Stats and R_ blog, apart from minor changes, reflecting personal taste and the use of code chunks in a Quarto, an open-source scientific and technical publishing system[^5] and the preference for a long data format (working with one team (= one observation) per row)[^6].  

```{r chunk01}
#| echo: true                      # show code in output doc
#| warning: false                  # hide warnings in output doc
#| message: false                  # hide messages in output doc
# ==============================================================================
# Simulation, following the method of AS
# ==============================================================================
# FUNCTIONS
# ------------------------------------------------------------------------------
cmps_team_as <- function(n_persons) {
#
# Draw a team: compose a team of n_persons, the AS way. 
# Dataframe df contains one row with n_persons two-letter initials, AS style, 
# and the last column is the percentage of unique initials in this team 
# composition.
#
  df <-replicate(n_persons, 
                 paste0(sample(LETTERS, size = 1), 
                        sample(LETTERS, size = 1)))
  df <-  as.data.frame(t(df))
  df$count <- apply(df,1,function(x) sum(!duplicated(x)))
  df$count <- 100*df$count/n_persons
  return(df)
}
# ------------------------------------------------------------------------------
#
# Set the number of persons in a team and the number of teams to be composed 
# (= number of repeats)
#
n_persons <- 8     # number of persons per team [AS: 8]
n_teams <- 1000    # number of repeats (teams)  [AS: 1000]
n_exper <- 100     # number of experiments      [AS:  100]
#
d_as <- as.data.frame(matrix(data=NA, ncol=2, nrow=n_exper))
#
repro <- FALSE  # set TRUE for reproducible random numbers
#
# Filename for file to accept team compositions, delete first
# if old file exists
#
fl <- "exp_results.csv"
if (file.exists(fl)) {
  file.remove(fl)
  fate <- "File deleted"
} else {
  fate <- "No file found"
}
#
for (xp in 1:n_exper) {
#
# Set a seed and compose the first team
#
zaad <- xp
#
if (repro == TRUE) {
  set.seed(zaad)
}
else
{
 a=as.numeric(Sys.time())
 set.seed(a)
}
#
teams <- cmps_team_as(n_persons)
#
# Fill up the teams dataframe with the remaining teams
#
for (i in 2:n_teams) { 
   team <- cmps_team_as(n_persons)
   teams <- rbind(teams, team)
}
#
cnt_unique <- length(which(teams$count==100))
pct_multip <- 100*(1-cnt_unique/n_teams)
#
# Use write.table to append teams to the file
# (as write.csv overwrites even with append=TRUE (?)
#
write.table(teams, file=fl, append = TRUE, row.names=FALSE, , sep=',')
#
d_as[xp, 1] <- fl
d_as[xp, 2] <- pct_multip
}
#
n_as <- length(d_as)
m_as <- mean(d_as[,2])
s_as <- sd(d_as[,2])
rsd_as <- 100*s_as/m_as
```
 
Based on the data, a mean of `{r} round(m_as,digits=2)` % is observed, with a standard deviation of `{r} round(s_as,digits=2)` %. Which is pretty much the same result as AS in his original post.

One further modification is needed if I want to use a different probability profile for the letters. I made some changes to the code but kept it such that a uniform letter probability can still be used as before, as a validation tool as well.  

```{r chunk02}
#| echo: true                      # show code in output doc
#| warning: false                  # hide warnings in output doc
#| message: false                  # hide messages in output doc
# ==============================================================================
# Simulation, allowing non-uniform distribution of letters
# ==============================================================================
# FUNCTIONS
# ------------------------------------------------------------------------------#
cmps_team_gh <- function(n_persons, df_p) {
#
# Draw a team: compose a team of n_persons, the GH way. 
# Supply a dataframe with probabilities for all letters in df_p
# Output dataframe df contains one row with n_persons two-letter initials, 
# and the last column is the percentage of unique initials in this team 
# composition.
#
  team <- replicate(n_persons, NA)
  for (i in 1:n_persons) { 
# 
# Draw the first initial, then the second and add to the team
# 
    urn <- runif(2)
    check <- which(with(df_p, df_p$low <= urn[1] & df_p$high > urn[1]))
    lttr <- df_p$lttr[check]
    check <- which(with(df_p, df_p$low <= urn[2] & df_p$high > urn[2]))
    lttr <- paste0(lttr, df_p$lttr[check])
    team[i] <- lttr
    }
#
  df <- team
  df <-  as.data.frame(t(df))
  df$count <- apply(df,1,function(x) sum(!duplicated(x)))
  df$count <- 100*df$count/n_persons
  return(df)
}
# ------------------------------------------------------------------------------
#
# Define the probability distribution function
#
# All letters have equal probability of occurence in this case
#
df_p <- data.frame(lttr = LETTERS, prob = replicate(26, 1/26))
#
# Prepare to pass on to random draw
#
colnames(df_p) <- c('lttr', 'low')
df_p$high <- df_p$low
#
df_p[1,2] <- 0.00
df_p[26,3] <- 1.00
#
for (i in 2:26) { 
  j <- i-1
  df_p[i,3] <- df_p[j,3]+df_p[i,2]
  df_p[i,2] <- df_p[j,3]
}
#
# ------------------------------------------------------------------------------
#
# Set the number of persons in a team and the number of teams to be composed 
# (= number of repeats)
#
n_persons <- 8     # number of persons per team [AS: 8]
n_teams <- 1000    # number of repeats (teams)  [AS: 1000]
n_exper <-100      # number of experiments      [AS:  100]
#
d_gh <- as.data.frame(matrix(data=NA, ncol=2, nrow=n_exper))
#
repro <- FALSE  # set TRUE for reproducible random numbers
#
for (xp in 1:n_exper) {
#
# Set a seed and compose the first team
#
zaad <- xp
#
if (repro == TRUE) {
  set.seed(zaad)
}
else
{
 a=as.numeric(Sys.time())
 set.seed(a)
}
teams <- cmps_team_gh(n_persons, df_p)
#
# Fill up the teams dataframe with the remaining teams
#   
for (i in 2:n_teams) { 
   team <- cmps_team_gh(n_persons, df_p)
   teams <- rbind(teams, team)
}
#
cnt_unique <- length(which(teams$count==100))
pct_multip <- 100*(1-cnt_unique/n_teams)
#
# Uncomment for writing csv data files per experiment
#
flx <- paste0('exp_', formatC(xp, width=4, flag="0"))
#
d_gh[xp, 1] <- flx
d_gh[xp, 2] <- pct_multip
}
#
n_gh <- length(d_gh)
m_gh <- mean(d_gh[,2])
s_gh <- sd(d_gh[,2])
rsd_gh <- 100*s_gh/m_gh
```

Based on the data from this modified code, a mean of `{r} round(m_gh,digits=2)` % is observed, with a standard deviation of `{r} round(s_gh,digits=2)` %. Again, taking into account the random nature of the process, pretty much the same result as AS.

The results can be compared in the following boxplot. The blue boxes have their usual meanings in the geom_boxplot context. The lower and upper hinges correspond to the first and third quartiles (the 25th and 75th percentiles). The upper whisker extends from the hinge to the largest value no further than 1.5 * IQR from the hinge (where IQR is the inter-quartile range, or distance between the first and third quartiles). The lower whisker extends from the hinge to the smallest value at most 1.5 * IQR of the hinge. I added the mean (red dot) as well, The green horizontal line corresponds to the actual probabilistic outcome.

```{r chunk03}
#| echo: false                     # hide code printing in output doc
#| warning: false                  # hide warnings in output doc
#| message: false                  # hide messages in output doc
# ==============================================================================
# Creates a boxplot from the d_as and d_gh dataframes
#
# GHUY: included for completeness and reference, for actual calculation of new 
#       data, uncomment # chunk03_01 and # chunk03_02. Otherwise a pre-recorded 
# image using this code is used.
# ==============================================================================
#
# Load Libraries to be used
#
library(ggplot2)
library(ggbeeswarm)
library(viridis)
#
# Bind the columns with data together (n_exper rows with the percentage of 
# duplicates for the AS and GH algorithm respectively)
#
d_cm <- as.data.frame(cbind(d_as[, 2],d_gh[, 2]))
colnames(d_cm) <- c('AS', 'GH')
#
d_cm_tidy <- tidyr::pivot_longer(d_cm, cols=c(AS,GH))
#
box <- ggplot(d_cm_tidy, aes(x=name, y=value, color=name)) +
       geom_boxplot(width=0.3, color="blue", alpha=0.2, staplewidth=0.5, outlier.shape=NA) +
       scale_color_viridis(discrete = TRUE, option="H") +
       geom_beeswarm(alpha=0.50, size=0.5) +
       stat_summary(fun.y=mean, geom="point", shape=20, size=5, color="red", fill="white") +
       geom_hline(yintercept=4.07218, color="green",width=0.5) +
       scale_y_continuous(limits = c(1, 7), breaks = seq(1, 7, by = 0.5)) + 
       labs(title = "",
            subtitle = "",
#           caption = expression(paste(italic("Source: GHUY'S SILVA RERUM"))),
            x = "Code",
            y = "Probability of duplicate two-letter initials (%)") +
#
    theme_bw() +
    theme(
      legend.position="none",
      plot.title = element_text(size=12, color="black"),
      axis.title = element_text(size=10, color="black"),
      axis.text = element_text(size=8, color="black") 
      )
#
ggsave("img/chunk03_1.png", box, width=10, height=10, units = "cm", dpi=300)
ggsave("img/chunk03_1_thumb.png", box, width=6.40, height=3.60, units = "in", dpi=100)
#
```

```{r chunk04}
#| label: fig-1
#| fig-cap: "Comparative boxplot"
#| fig-pos: "!h"                   # insist on putting the figure here 
#| fig-align: "center"             # align the figure on the page
#| out-width: 50%                  # use half of the page width
#| echo: false                     # hide code printing in output doc
#| warning: false                  # hide warnings in output doc
#| message: false                  # hide messages in output doc
#
img_path <- "img/chunk03_1.png"
knitr::include_graphics(img_path)
```

### Reflections

The results are quite similar, re-running the simulations with different random numbers will change the results somewhat. However the general conclusion about the magnitude of the probability of having duplicate two-letter initials remains valid. 

For the current purpose, having a rough idea about the probability of duplicate two-letter initials in teams of eight people, this may suffice. 

What strikes me however is the pretty large Relative Standard Deviation (aka Coefficient of Variation). In this set of experiments we find `{r} round(rsd_as,digits=1)`% and `{r} round(rsd_gh,digits=1)`% for the AS and GH case respectively. Note that the result is indeed random. Sometimes the first case (AS) gives a smaller Relative Standard Deviation, sometimes the second (GH). 

The Relative Standard Deviation is however higher than I expected. After all, we ran quite some simulations. This raises questions on how the mean and standard deviation depend on the choices of the parameters. Something to explore later.

For now, I conclude that I have validated the code and that I can use it for a next post. For the time being the same set of parameters (1000 as the number of repeats and 100 as the number of experiments) will be used there.

```{r chunk05}
#| echo: false                      # show code in output doc
#| warning: false                  # hide warnings in output doc
#| message: false                  # hide messages in output doc
# ==============================================================================
#
library(stringr)
#
pex_as <- 100/26/26                # probability (%) for each two-letter initial
n_exper <- 100                     # check other chunks for correct value!
n_teams <- 1000                    # check other chunks for correct value!  
#
n_draws <- n_exper*n_teams
n_expct <- n_draws/26/26
#
file <- "exp_results.csv"
df_exp <- read.csv(file, header=TRUE, stringsAsFactors = FALSE)
#
# Remove the experiment headers of the experiments (all but the first rows that 
# have "count" in the 9th column 
#
df_exp <- df_exp[!df_exp$count == "count", ]
#
df_ini <- df_exp[,-9]
#
ch <- "AS"

count <- str_count(df_ini[,8], ch)

df_ini[,9] <- as.numeric(str_count(df_ini[,8], ch))
#count  <- str_count(df_ini[,1:7], ch)
df_ini[,10] <- as.numeric(0)
for (i in 1:7){
  df_ini[,10] <- df_ini[,10]+as.numeric(str_count(df_ini[,i], ch))
}
#
n_as_newmember <- length(which(df_ini$V9==1))
n_as_oldmember <- length(which(df_ini$V10==1))
n_as_oldmember2 <- length(which(df_ini$V10==2))
n_as_oldmember3 <- length(which(df_ini$V10==3))

df_sol <- subset(df_ini,(V9==1 & V10>0))
n_as_simul <- nrow(df_sol)
psm_as <- 100*n_as_simul/n_draws
#
```

Note that, on the fly, we "penciled down" all teams (`{r} as.integer(n_exper)` x `{r} as.integer(n_teams)` repeats, or `{r} as.integer(n_draws)` teams).  

This allows us to do a lot more with the data. It all started with a person with a given two-letter initial joining an existing team of seven people. 

The probability of having a given specific two-letter initial (say AS, XY or QQ) under the assumed conditions (ie all letters are created equal) is `{r} round(pex_as,digits=6)` %. So, if we would be drawing `{r} as.integer(n_draws)` times, each combination would pop up `{r} round(n_expct,digits=2)` times.   

For the simulated data we can tally the number of teams that have specific members on board. Say we are looking for "AS" (does not really matter here as all letters are created equal). 

- Teams with "AS" as "member eight" of the team: `{r} n_as_newmember` (compare to our expected `{r} round(n_expct,digits=2)`),
- Teams with one "AS" as old member ("member 1 through 7"): `{r} n_as_oldmember` ,
- Teams with two old "AS" members: `{r} n_as_oldmember2`,  
- Teams with three "AS" members in the original team: `{r} n_as_oldmember3`,

But what we are actually looking for is adding "AS" as the eighth member to a team of seven people, where there is already one (or more) "AS" in the original team. It turns out that, in this simulation, there are only `{r} n_as_simul` out of `{r} as.integer(n_draws)` teams. Or a probability of only `{r} round(psm_as,digits=6)` %. So indeed quite a rare event. 


[^1]: https://statsandr.com/
[^2]: Stats and R - 2023-12-06 - What is the probability that two persons have the same initials?
[^3]: A *Universally Unique Identifier (UUID)* is a 128-bit label used for information in computer systems. The term *Globally Unique Identifier (GUID)* is also used. https://en.wikipedia.org/wiki/Universally_unique_identifier
[^4]: R package ‘uuid’, version 1.2-1, July 29, 2024
[^5]: Quarto, an open-source scientific and technical publishing system, https://quarto.org/
[^6]: Wickham, H. (2014). Tidy Data. Journal of Statistical Software, 59(10), 1–23. https://doi.org/10.18637/jss.v059.i10

[^m]: M&M's are color-varied sugar-coated dragée chocolate confectionery, each of which has the letter "m" printed in lower case in white on one side. M&M'S is a trademark of MARS, Inc. https://en.wikipedia.org/wiki/M%26M%27s
[^mm]: Well huge... 676 M&Ms to be precise. A traditional milk chocolate M&M weighs about 0.91 grams, so about 615 g (or some 3.2 kcal).

